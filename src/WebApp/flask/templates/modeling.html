{% extends "layout.html" %}

{% block body %}
<div class="modeling col-md-12 col-sm-12">
    <p>
        The following steps of the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview">Team Data Science Process (TDSP)</a> are typically associated with the role of the Data Scientist:
        <ul>
            <li>Data acquisition and understanding</li>
            <li>Feature engineering</li>
            <li>Model training</li>
            <li>Model evaluation</li>
            <li>Model operationalization (deployment)</li>
        </ul>
    </p>
    <h5>Notes on solution's Data Science sample</h5>
    <p>
        The sample notebooks can run on various compute targets.
        In most situations, <i>Linux Data Science Virtual Machine (DSVM)</i> will be sufficient to perform feature engineering and model training.
        Feature engineering requires a <i>Spark</i> cluster; that is to enable scenarios with arbitrarily large input data sets.
        Typically (in the context of Predictive Maintenance), the size of input data is drastically reduced following the feature engineering step. For that reason, <i>Spark</i>'s <i>MLlib</i> was not used to perform model training.
    </p>
    <h5>
        Choose a compute target and follow the instructions
    </h5>

    <ul class="nav nav-pills mb-3" id="pills-tab" role="tablist">
        <li class="nav-item">
            <a class="nav-link active" id="pills-home-tab" data-toggle="pill" href="#pills-dsvm" role="tab" aria-controls="pills-home" aria-selected="true">Linux DSVM</a>
        </li>
        <li class="nav-item">
            <a class="nav-link" id="pills-profile-tab" data-toggle="pill" href="#pills-databricks" role="tab" aria-controls="pills-profile" aria-selected="false">Azure Databricks</a>
        </li>
        <li class="nav-item">
            <a class="nav-link" id="pills-contact-tab" data-toggle="pill" href="#pills-aztk" role="tab" aria-controls="pills-contact" aria-selected="false">AZTK</a>
        </li>
        <li class="nav-item">
            <a class="nav-link" id="pills-contact-tab" data-toggle="pill" href="#pills-local" role="tab" aria-controls="pills-contact" aria-selected="false">Local</a>
        </li>
    </ul>
    <div class="tab-content" id="pills-tabContent">
        <div class="tab-pane fade show active" id="pills-dsvm" role="tabpanel" aria-labelledby="pills-home-tab">
            <img class="target-logo" src="https://106c4.wpc.azureedge.net/80106C4/Gallery-Prod/cdn/2015-02-24/prod20161101-microsoft-windowsazure-gallery/microsoft-ads.linux-data-science-vm-ubuntulinuxdsvmubuntu.1.0.13/Icons/Large.png" />
            <p>
                A pre-configured instance of the Linux DSVM has been deployed as part of the solution. Please navigate to <a href="https://{{dsvmName}}:8000" target="_blank">Jupyter Notebooks</a> to continue.
            </p>
            <p>
                Ignore certificate warnings if any.
            </p>
        </div>
        <div class="tab-pane fade" id="pills-databricks" role="tabpanel" aria-labelledby="pills-profile-tab">
            <img class="target-logo" src="https://azure.microsoft.com/svghandler/databricks/?width=130&height=130" />
            <p>
                <strong>Note</strong>: Only data acquisition (ingestion) and feature engineering are supported on Databricks.
            </p>
            <p>
                To continue, please navigate to <a href="{{databricks_workspace}}" target="_blank">your Databricks Workspace</a>
                and create a cluster following <a href="https://docs.databricks.com/user-guide/clusters/create.html" target="_blank">these instructions</a>.
                Make sure to provide configuration parameters as shown below.
            </p>
            <img src ="{{ url_for('static', filename='databricks_cluster_creation.jpg') }}" class="thumbnail" />
            <ol>
                <li>
                    Create <code>azure-storage</code> (Upload Python Egg or PyPI) and <code>com.databricks:spark-avro_2.11:4.0.0</code> (Maven Coordinate) libraries (<a target="_blank" href="https://docs.databricks.com/user-guide/libraries.html#create-a-library">instructions</a>).
                </li>
                <li>
                    Attach both libraries to the cluster (<a target="_blank" href="https://docs.databricks.com/user-guide/libraries.html#attach-a-library-to-a-cluster">instructions</a>).
                </li>
                <li>
                    Ingest input data by following one of the steps below.
                    <ol>
                        <li>Generate seed data on DSVM (by running DataGeneration.ipynb notebook) and copy it to Databricks as follows:<br>
                        <code>dbfs cp -r ~/data/telemetry dbfs:/root/data/telemetry</code><br/>
                        <code>dbfs cp -r ~/data/logs dbfs:/root/data/logs</code>
                    </li>
                    <li>Run the DataIngestion notebook on Databricks to ingest IoT telemetry and device logs</li>
                    </ol>
                </li>
                <li>
                    Run the Feature Engineering notebook
                </li>
                <li>
                    Copy the feature data set produced by the Feature Engineering notebook back to DSVM:<br />
                    <code>rm -r ~/data/features</code><br/>
                    <code>dbfs cp -r dbfs:/root/data/features ~/data/features</code><br/>
                </li>
                <li>
                    Continue with model training and operationalization on DSVM
                </li>
            </ol>
        </div>
        <div class="tab-pane fade" id="pills-aztk" role="tabpanel" aria-labelledby="pills-contact-tab">
            <p>
                Instructions will be provided soon.
            </p>
        </div>
        <div class="tab-pane fade" id="pills-local" role="tabpanel" aria-labelledby="pills-contact-tab">
            <p>
                Instructions will be provided soon.
            </p>
        </div>
    </div>
</div>
{% endblock %}
