{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Avro Blobs Into Parquet Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, SQLContext, Window\n",
    "from pyspark.sql.functions import udf, mean, lit, stddev, col, expr, when, date_sub, avg, window\n",
    "from pyspark.sql.types import DoubleType, ArrayType, ShortType, LongType, IntegerType, TimestampType, StructType, StringType, StructField\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "from azure.storage.table import TableService, Entity, TablePermissions\n",
    "\n",
    "STORAGE_ACCOUNT_SUFFIX = 'core.windows.net'\n",
    "TELEMETRY_STORAGE_ACCOUNT_NAME = os.getenv('TELEMETRY_STORAGE_ACCOUNT_NAME')\n",
    "TELEMETRY_STORAGE_ACCOUNT_KEY = os.getenv('TELEMETRY_STORAGE_ACCOUNT_KEY')\n",
    "TABLE_STORAGE_ACCOUNT_NAME = os.getenv('TABLE_STORAGE_ACCOUNT_NAME') #TODO need to add to ENV Variables\n",
    "TABLE_STORAGE_ACCOUNT_KEY = os.getenv('TABLE_STORAGE_ACCOUNT_KEY') #TODO need to add to ENV Variables\n",
    "TELEMETRY_CONTAINER_NAME = os.getenv('TELEMETRY_CONTAINER_NAME')\n",
    "#LOGS_ARCHIVE_CONTAINER_NAME = 'logs-archive' #TODO: introduce environment variables\n",
    "STAGING_STORAGE_ACCOUNT_NAME = os.getenv('STAGING_STORAGE_ACCOUNT_NAME')\n",
    "STAGING_STORAGE_ACCOUNT_KEY = os.getenv('STAGING_STORAGE_ACCOUNT_KEY')\n",
    "LOG_TABLE_NAME = os.getenv('LOG_TABLE_NAME') #TODO need to add this to ENV Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For development purposes only until ENV Variables get set\n",
    "STORAGE_ACCOUNT_SUFFIX = 'core.windows.net'\n",
    "TELEMETRY_STORAGE_ACCOUNT_NAME = \"stguwsjc4vojbrbw\"\n",
    "TELEMETRY_STORAGE_ACCOUNT_KEY = \"2GGDWVBtGBy+hAgl5a1uGT4NeU2zzFdocuDFKnOwR2vc5wEOP7jTfbS3/Nl5vvzEudJ4nfH6ozmSOSPXo3xETA==\"\n",
    "TABLE_STORAGE_ACCOUNT_NAME = \"stguwsjc4vojbrbw\"\n",
    "TABLE_STORAGE_ACCOUNT_KEY = \"2GGDWVBtGBy+hAgl5a1uGT4NeU2zzFdocuDFKnOwR2vc5wEOP7jTfbS3/Nl5vvzEudJ4nfH6ozmSOSPXo3xETA==\"\n",
    "TELEMETRY_CONTAINER_NAME = \"telemetry\"\n",
    "#LOGS_ARCHIVE_CONTAINER_NAME = \"logs\" #TODO: introduce environment variables\n",
    "STAGING_STORAGE_ACCOUNT_NAME = \"stguwsjc4vojbrbw\"\n",
    "STAGING_STORAGE_ACCOUNT_KEY = \"2GGDWVBtGBy+hAgl5a1uGT4NeU2zzFdocuDFKnOwR2vc5wEOP7jTfbS3/Nl5vvzEudJ4nfH6ozmSOSPXo3xETA==\"\n",
    "LOG_TABLE_NAME = 'cycles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = str(Path.home()) + '/data'\n",
    "\n",
    "#TODO: Convert data_dir into env variable\n",
    "% rm -rf $data_dir\n",
    "% mkdir $data_dir $data_dir/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+\n",
      "|     EnqueuedTimeUtc|Properties|    SystemProperties|                Body|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wasbTelemetryUrl = \"wasb://{0}@{1}.blob.{2}/*/*/*/*/*/*/*\".format(TELEMETRY_CONTAINER_NAME, \n",
    "                                                                  TELEMETRY_STORAGE_ACCOUNT_NAME, \n",
    "                                                                  STORAGE_ACCOUNT_SUFFIX)\n",
    "\n",
    "sc = SparkSession.builder.getOrCreate()\n",
    "hc = sc._jsc.hadoopConfiguration()\n",
    "hc.set(\"avro.mapred.ignore.inputs.without.extension\", \"false\")\n",
    "if TELEMETRY_STORAGE_ACCOUNT_KEY:\n",
    "     hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\".format(TELEMETRY_STORAGE_ACCOUNT_NAME), TELEMETRY_STORAGE_ACCOUNT_KEY)\n",
    "hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\"\n",
    "    .format(STAGING_STORAGE_ACCOUNT_NAME), STAGING_STORAGE_ACCOUNT_KEY)\n",
    "sql = SQLContext.getOrCreate(sc)\n",
    "avroblob = sql.read.format(\"com.databricks.spark.avro\").load(wasbTelemetryUrl)\n",
    "avroblob.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EnqueuedTimeUtc: string (nullable = true)\n",
      " |-- Properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- SystemProperties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- Body: binary (nullable = true)\n",
      " |-- BodyString: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert byteformat to string format in pyspark dataframe\n",
    "from json import loads as Loads\n",
    "column = avroblob['Body']\n",
    "string_udf = udf(lambda x: x.decode(\"utf-8\"))\n",
    "avroblob=avroblob.withColumn(\"BodyString\", string_udf(column))\n",
    "avroblob.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+-----------+--------+-------+-------------+-----------+--------------------+---------+\n",
      "|ambient_pressure|ambient_temperature|  machineID|pressure|  speed|speed_desired|temperature|           timestamp|vibration|\n",
      "+----------------+-------------------+-----------+--------+-------+-------------+-----------+--------------------+---------+\n",
      "|          100.92|              20.06|Machine-004|  655.58|1133.27|         1000|     174.62|2018-06-20T16:41:...|     null|\n",
      "|          101.02|              19.95|Machine-001|   46.46|  -2.17|            0|     164.84|2018-06-20T16:41:...|     null|\n",
      "|          101.04|              20.06|Machine-004|  673.66|1131.69|         1000|     174.71|2018-06-20T16:41:...|     null|\n",
      "|          101.07|              20.05|Machine-001|   70.93|   1.97|            0|     164.95|2018-06-20T16:41:...|     null|\n",
      "|           101.1|               19.9|Machine-004|  660.65|1138.23|         1000|     174.63|2018-06-20T16:41:...|     null|\n",
      "|          100.94|              19.94|Machine-001|  211.62| 560.03|         1000|     138.58|2018-06-20T16:41:...|     null|\n",
      "|          101.05|              20.06|Machine-001|  482.56| 829.28|         1000|     138.49|2018-06-20T16:41:...|     null|\n",
      "|          100.93|              20.07|Machine-001|  768.96| 967.38|         1000|     138.42|2018-06-20T16:41:...|     null|\n",
      "|          100.97|              20.05|Machine-001| 1014.26|1038.19|         1000|     138.43|2018-06-20T16:41:...|     null|\n",
      "|          101.03|              20.09|Machine-001| 1176.04|1074.96|         1000|     138.61|2018-06-20T16:41:...|     null|\n",
      "|          100.92|              19.93|Machine-004|  668.61|1137.07|         1000|     174.73|2018-06-20T16:41:...|     null|\n",
      "|          100.91|              20.04|Machine-004|  660.71|1136.41|         1000|     174.74|2018-06-20T16:41:...|     null|\n",
      "|          100.95|              19.91|Machine-001|   52.92|  -2.84|            0|     164.96|2018-06-20T16:41:...|     null|\n",
      "|          101.05|              20.09|Machine-001|   68.23|   2.02|            0|     164.94|2018-06-20T16:41:...|     null|\n",
      "|          101.07|              20.02|Machine-001|   45.18|   1.46|            0|     164.92|2018-06-20T16:41:...|     null|\n",
      "|          101.04|              20.06|Machine-001|   56.86|    4.3|            0|     165.02|2018-06-20T16:41:...|     null|\n",
      "|          100.95|              19.92|Machine-004|  639.36|1131.49|         1000|     174.83|2018-06-20T16:41:...|     null|\n",
      "|          100.97|              19.96|Machine-001|   45.55|   2.79|            0|      164.9|2018-06-20T16:41:...|     null|\n",
      "|          101.04|              20.03|Machine-004|  664.96| 1136.1|         1000|     174.74|2018-06-20T16:41:...|     null|\n",
      "|          101.04|               20.0|Machine-001|   77.71|   4.97|            0|      165.0|2018-06-20T16:41:...|     null|\n",
      "+----------------+-------------------+-----------+--------+-------+-------------+-----------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe into \n",
    "new_df = sql.read.json(avroblob.select(\"BodyString\").rdd.map(lambda r: r.BodyString))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.write.parquet(data_dir+\"/telemetry\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table retrieval\n",
    "table_service = TableService(account_name=TABLE_STORAGE_ACCOUNT_NAME, account_key=TABLE_STORAGE_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get logs?\n",
    "tblob = table_service.query_entities(LOG_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpeedAvg</th>\n",
       "      <th>PartitionKey</th>\n",
       "      <th>etag</th>\n",
       "      <th>TemperatureMax</th>\n",
       "      <th>RowKey</th>\n",
       "      <th>SpeedDesiredMax</th>\n",
       "      <th>RawCount</th>\n",
       "      <th>CycleEnd</th>\n",
       "      <th>PressureAvg</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PressureMax</th>\n",
       "      <th>TemperatureAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1112.203945</td>\n",
       "      <td>Machine-000</td>\n",
       "      <td>W/\"datetime'2018-06-19T18%3A09%3A07.5890441Z'\"</td>\n",
       "      <td>137.88</td>\n",
       "      <td>2018-06-19 18:02:15.669</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>578</td>\n",
       "      <td>2018-06-19 18:07:05.214</td>\n",
       "      <td>1484.384498</td>\n",
       "      <td>2018-06-19 18:09:07.589044</td>\n",
       "      <td>1545.88</td>\n",
       "      <td>134.648235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>956.581250</td>\n",
       "      <td>Machine-000</td>\n",
       "      <td>W/\"datetime'2018-06-19T18%3A11%3A41.9128297Z'\"</td>\n",
       "      <td>137.91</td>\n",
       "      <td>2018-06-19 18:08:06.23</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>240</td>\n",
       "      <td>2018-06-19 18:10:06.761</td>\n",
       "      <td>1302.244250</td>\n",
       "      <td>2018-06-19 18:11:41.912829</td>\n",
       "      <td>1544.61</td>\n",
       "      <td>137.803750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>765.731667</td>\n",
       "      <td>Machine-000</td>\n",
       "      <td>W/\"datetime'2018-06-19T18%3A13%3A50.288937Z'\"</td>\n",
       "      <td>137.92</td>\n",
       "      <td>2018-06-19 18:11:07.768</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>2018-06-19 18:12:07.022</td>\n",
       "      <td>1071.589333</td>\n",
       "      <td>2018-06-19 18:13:50.288937</td>\n",
       "      <td>1544.25</td>\n",
       "      <td>137.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020.737889</td>\n",
       "      <td>Machine-000</td>\n",
       "      <td>W/\"datetime'2018-06-19T18%3A17%3A52.8713843Z'\"</td>\n",
       "      <td>137.96</td>\n",
       "      <td>2018-06-19 18:13:08.03</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>360</td>\n",
       "      <td>2018-06-19 18:16:09.293</td>\n",
       "      <td>1374.879333</td>\n",
       "      <td>2018-06-19 18:17:52.871384</td>\n",
       "      <td>1543.93</td>\n",
       "      <td>137.856500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021.222056</td>\n",
       "      <td>Machine-000</td>\n",
       "      <td>W/\"datetime'2018-06-19T18%3A21%3A58.1727587Z'\"</td>\n",
       "      <td>138.00</td>\n",
       "      <td>2018-06-19 18:17:10.299</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>360</td>\n",
       "      <td>2018-06-19 18:20:10.33</td>\n",
       "      <td>1372.087889</td>\n",
       "      <td>2018-06-19 18:21:58.172758</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>137.885667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SpeedAvg PartitionKey                                            etag  \\\n",
       "0  1112.203945  Machine-000  W/\"datetime'2018-06-19T18%3A09%3A07.5890441Z'\"   \n",
       "1   956.581250  Machine-000  W/\"datetime'2018-06-19T18%3A11%3A41.9128297Z'\"   \n",
       "2   765.731667  Machine-000   W/\"datetime'2018-06-19T18%3A13%3A50.288937Z'\"   \n",
       "3  1020.737889  Machine-000  W/\"datetime'2018-06-19T18%3A17%3A52.8713843Z'\"   \n",
       "4  1021.222056  Machine-000  W/\"datetime'2018-06-19T18%3A21%3A58.1727587Z'\"   \n",
       "\n",
       "   TemperatureMax                   RowKey  SpeedDesiredMax RawCount  \\\n",
       "0          137.88  2018-06-19 18:02:15.669           1000.0      578   \n",
       "1          137.91   2018-06-19 18:08:06.23           1000.0      240   \n",
       "2          137.92  2018-06-19 18:11:07.768           1000.0      120   \n",
       "3          137.96   2018-06-19 18:13:08.03           1000.0      360   \n",
       "4          138.00  2018-06-19 18:17:10.299           1000.0      360   \n",
       "\n",
       "                  CycleEnd  PressureAvg                  Timestamp  \\\n",
       "0  2018-06-19 18:07:05.214  1484.384498 2018-06-19 18:09:07.589044   \n",
       "1  2018-06-19 18:10:06.761  1302.244250 2018-06-19 18:11:41.912829   \n",
       "2  2018-06-19 18:12:07.022  1071.589333 2018-06-19 18:13:50.288937   \n",
       "3  2018-06-19 18:16:09.293  1374.879333 2018-06-19 18:17:52.871384   \n",
       "4   2018-06-19 18:20:10.33  1372.087889 2018-06-19 18:21:58.172758   \n",
       "\n",
       "   PressureMax  TemperatureAvg  \n",
       "0      1545.88      134.648235  \n",
       "1      1544.61      137.803750  \n",
       "2      1544.25      137.835000  \n",
       "3      1543.93      137.856500  \n",
       "4      1543.10      137.885667  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = list()\n",
    "for row in tblob:\n",
    "    if (len(attributes) == 0):\n",
    "        for attribute in row:\n",
    "            attributes.append(attribute)\n",
    "    break\n",
    "log_df = pd.DataFrame(columns=attributes)\n",
    "for row in tblob:\n",
    "    row_dict = {}    \n",
    "    for attribute in row:\n",
    "        if (attribute != \"Timestamp\"):\n",
    "            row_dict[attribute] = row[attribute]\n",
    "        else:\n",
    "            newtime = row[attribute].replace(tzinfo=None)\n",
    "            timeitem = pd.Timestamp(newtime, tz=None)\n",
    "            row_dict[attribute] = timeitem\n",
    "    log_df = log_df.append(row_dict, ignore_index=True)\n",
    "del log_df[\"RollingWindow\"]\n",
    "log_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Spark - local",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
