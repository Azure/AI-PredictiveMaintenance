{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Avro Blobs Into Parquet Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, SQLContext, Window\n",
    "from pyspark.sql.functions import udf, mean, lit, stddev, col, expr, when, date_sub, avg, window\n",
    "from pyspark.sql.types import DoubleType, ArrayType, ShortType, LongType, IntegerType, TimestampType, StructType, StringType, StructField\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "\n",
    "STORAGE_ACCOUNT_SUFFIX = 'core.windows.net'\n",
    "TELEMETRY_STORAGE_ACCOUNT_NAME = \"stguwsjc4vojbrbw\"\n",
    "TELEMETRY_STORAGE_ACCOUNT_KEY = \"2GGDWVBtGBy+hAgl5a1uGT4NeU2zzFdocuDFKnOwR2vc5wEOP7jTfbS3/Nl5vvzEudJ4nfH6ozmSOSPXo3xETA==\"\n",
    "TELEMETRY_CONTAINER_NAME = \"telemetry\"\n",
    "LOGS_ARCHIVE_CONTAINER_NAME = 'logs-archive'\n",
    "STAGING_STORAGE_ACCOUNT_NAME = \"stguwsjc4vojbrbw\"\n",
    "STAGING_STORAGE_ACCOUNT_KEY = \"2GGDWVBtGBy+hAgl5a1uGT4NeU2zzFdocuDFKnOwR2vc5wEOP7jTfbS3/Nl5vvzEudJ4nfH6ozmSOSPXo3xETA==\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = str(Path.home()) + '/data'\n",
    "\n",
    "% rm -rf $data_dir\n",
    "% mkdir $data_dir $data_dir/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+\n",
      "|     EnqueuedTimeUtc|Properties|    SystemProperties|                Body|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "|2018-06-20T16:41:...|     Map()|Map(connectionAut...|[7B 22 6D 61 63 6...|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wasbTelemetryUrl = \"wasb://{0}@{1}.blob.{2}/*/*/*/*/*/*/*\".format(TELEMETRY_CONTAINER_NAME, \n",
    "                                                                  TELEMETRY_STORAGE_ACCOUNT_NAME, \n",
    "                                                                  STORAGE_ACCOUNT_SUFFIX)\n",
    "sc = SparkSession.builder.getOrCreate()\n",
    "hc = sc._jsc.hadoopConfiguration()\n",
    "hc.set(\"avro.mapred.ignore.inputs.without.extension\", \"false\")\n",
    "if TELEMETRY_STORAGE_ACCOUNT_KEY:\n",
    "     hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\".format(TELEMETRY_STORAGE_ACCOUNT_NAME), TELEMETRY_STORAGE_ACCOUNT_KEY)\n",
    "hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\"\n",
    "    .format(STAGING_STORAGE_ACCOUNT_NAME), STAGING_STORAGE_ACCOUNT_KEY)\n",
    "sql = SQLContext.getOrCreate(sc)\n",
    "avroblob = sql.read.format(\"com.databricks.spark.avro\").load(wasbTelemetryUrl)\n",
    "avroblob.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EnqueuedTimeUtc: string (nullable = true)\n",
      " |-- Properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- SystemProperties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- Body: binary (nullable = true)\n",
      " |-- BodyString: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert byteformat to string format in pyspark dataframe\n",
    "from json import loads as Loads\n",
    "column = avroblob['Body']\n",
    "string_udf = udf(lambda x: x.decode(\"utf-8\"))\n",
    "avroblob=avroblob.withColumn(\"BodyString\", string_udf(column))\n",
    "avroblob.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+-----------+--------+-------+-------------+-----------+--------------------+---------+\n",
      "|ambient_pressure|ambient_temperature|  machineID|pressure|  speed|speed_desired|temperature|           timestamp|vibration|\n",
      "+----------------+-------------------+-----------+--------+-------+-------------+-----------+--------------------+---------+\n",
      "|          100.92|              20.06|Machine-004|  655.58|1133.27|         1000|     174.62|2018-06-20T16:41:...|     null|\n",
      "|          101.02|              19.95|Machine-001|   46.46|  -2.17|            0|     164.84|2018-06-20T16:41:...|     null|\n",
      "|          101.04|              20.06|Machine-004|  673.66|1131.69|         1000|     174.71|2018-06-20T16:41:...|     null|\n",
      "|          101.07|              20.05|Machine-001|   70.93|   1.97|            0|     164.95|2018-06-20T16:41:...|     null|\n",
      "|           101.1|               19.9|Machine-004|  660.65|1138.23|         1000|     174.63|2018-06-20T16:41:...|     null|\n",
      "|          100.94|              19.94|Machine-001|  211.62| 560.03|         1000|     138.58|2018-06-20T16:41:...|     null|\n",
      "|          101.05|              20.06|Machine-001|  482.56| 829.28|         1000|     138.49|2018-06-20T16:41:...|     null|\n",
      "|          100.93|              20.07|Machine-001|  768.96| 967.38|         1000|     138.42|2018-06-20T16:41:...|     null|\n",
      "|          100.97|              20.05|Machine-001| 1014.26|1038.19|         1000|     138.43|2018-06-20T16:41:...|     null|\n",
      "|          101.03|              20.09|Machine-001| 1176.04|1074.96|         1000|     138.61|2018-06-20T16:41:...|     null|\n",
      "|          100.92|              19.93|Machine-004|  668.61|1137.07|         1000|     174.73|2018-06-20T16:41:...|     null|\n",
      "|          100.91|              20.04|Machine-004|  660.71|1136.41|         1000|     174.74|2018-06-20T16:41:...|     null|\n",
      "|          100.95|              19.91|Machine-001|   52.92|  -2.84|            0|     164.96|2018-06-20T16:41:...|     null|\n",
      "|          101.05|              20.09|Machine-001|   68.23|   2.02|            0|     164.94|2018-06-20T16:41:...|     null|\n",
      "|          101.07|              20.02|Machine-001|   45.18|   1.46|            0|     164.92|2018-06-20T16:41:...|     null|\n",
      "|          101.04|              20.06|Machine-001|   56.86|    4.3|            0|     165.02|2018-06-20T16:41:...|     null|\n",
      "|          100.95|              19.92|Machine-004|  639.36|1131.49|         1000|     174.83|2018-06-20T16:41:...|     null|\n",
      "|          100.97|              19.96|Machine-001|   45.55|   2.79|            0|      164.9|2018-06-20T16:41:...|     null|\n",
      "|          101.04|              20.03|Machine-004|  664.96| 1136.1|         1000|     174.74|2018-06-20T16:41:...|     null|\n",
      "|          101.04|               20.0|Machine-001|   77.71|   4.97|            0|      165.0|2018-06-20T16:41:...|     null|\n",
      "+----------------+-------------------+-----------+--------+-------+-------------+-----------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe into \n",
    "new_df = sql.read.json(avroblob.select(\"BodyString\").rdd.map(lambda r: r.BodyString))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '*.crc': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "new_df.write.parquet(data_dir+\"/telemetry\", mode=\"overwrite\")\n",
    "% rm \"*.crc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Spark - local",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
