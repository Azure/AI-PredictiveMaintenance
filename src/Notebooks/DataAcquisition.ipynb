{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Avro Blobs Into Parquet Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, SQLContext, Window\n",
    "from pyspark.sql.functions import udf, mean, lit, stddev, col, expr, when, date_sub, avg, window\n",
    "from pyspark.sql.types import DoubleType, ArrayType, ShortType, LongType, IntegerType, TimestampType, StructType, StringType, StructField\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "\n",
    "STORAGE_ACCOUNT_SUFFIX = 'core.windows.net'\n",
    "TELEMETRY_STORAGE_ACCOUNT_NAME = os.getenv('TELEMETRY_STORAGE_ACCOUNT_NAME')\n",
    "TELEMETRY_STORAGE_ACCOUNT_KEY = os.getenv('TELEMETRY_STORAGE_ACCOUNT_KEY')\n",
    "TELEMETRY_CONTAINER_NAME = os.getenv('TELEMETRY_CONTAINER_NAME')\n",
    "LOGS_ARCHIVE_CONTAINER_NAME = 'logs-archive' #TODO: introduce environment variables\n",
    "STAGING_STORAGE_ACCOUNT_NAME = os.getenv('STAGING_STORAGE_ACCOUNT_NAME')\n",
    "STAGING_STORAGE_ACCOUNT_KEY = os.getenv('STAGING_STORAGE_ACCOUNT_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = str(Path.home()) + '/data'\n",
    "\n",
    "#TODO: Convert data_dir into env variable\n",
    "% rm -rf $data_dir\n",
    "% mkdir $data_dir $data_dir/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasbTelemetryUrl = \"wasb://{0}@{1}.blob.{2}/*/*/*/*/*/*/*\".format(TELEMETRY_CONTAINER_NAME, \n",
    "                                                                  TELEMETRY_STORAGE_ACCOUNT_NAME, \n",
    "                                                                  STORAGE_ACCOUNT_SUFFIX)\n",
    "sc = SparkSession.builder.getOrCreate()\n",
    "hc = sc._jsc.hadoopConfiguration()\n",
    "hc.set(\"avro.mapred.ignore.inputs.without.extension\", \"false\")\n",
    "if TELEMETRY_STORAGE_ACCOUNT_KEY:\n",
    "     hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\".format(TELEMETRY_STORAGE_ACCOUNT_NAME), TELEMETRY_STORAGE_ACCOUNT_KEY)\n",
    "hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\"\n",
    "    .format(STAGING_STORAGE_ACCOUNT_NAME), STAGING_STORAGE_ACCOUNT_KEY)\n",
    "sql = SQLContext.getOrCreate(sc)\n",
    "avroblob = sql.read.format(\"com.databricks.spark.avro\").load(wasbTelemetryUrl)\n",
    "avroblob.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert byteformat to string format in pyspark dataframe\n",
    "from json import loads as Loads\n",
    "column = avroblob['Body']\n",
    "string_udf = udf(lambda x: x.decode(\"utf-8\"))\n",
    "avroblob=avroblob.withColumn(\"BodyString\", string_udf(column))\n",
    "avroblob.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe into \n",
    "new_df = sql.read.json(avroblob.select(\"BodyString\").rdd.map(lambda r: r.BodyString))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.write.parquet(data_dir+\"/telemetry\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Spark - local",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
