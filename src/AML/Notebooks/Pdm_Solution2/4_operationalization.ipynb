{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Model operationalization & Deployment\n",
    "\n",
    "In this script, we load the model from the `Code/3_model_building.ipynb` Jupyter notebook and the labeled feature data set constructed in the `Code/2_feature_engineering.ipynb` notebook in order to build the model deployment artifacts. We create deployment functions, which we test locally in the notebook. We package a model schema file, the deployment run functions file, and the model created in the previous notebook into a deployment file. We load this package onto our Azure blob storage for deployment.\n",
    "\n",
    "The remainder of this notebook details steps required to deploy and operationalize the model using Azure Machine Learning Model Management environment for use in production in realtime.\n",
    "\n",
    "**Note:** This notebook will take about 1 minute to execute all cells, depending on the compute configuration you have setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup our environment by importing required libraries\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# for creating pipelines and model\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "\n",
    "# setup the pyspark environment\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "\n",
    "# For logging model evaluation parameters back into the\n",
    "# AML Workbench run history plots.\n",
    "import logging\n",
    "#nav from azureml.logging import get_azureml_logger\n",
    "\n",
    "amllog = logging.getLogger(\"azureml\")\n",
    "amllog.level = logging.INFO\n",
    "\n",
    "# Turn on cell level logging.\n",
    "#nav %azureml history on\n",
    "#nav %azureml history show\n",
    "\n",
    "# Time the notebook execution. \n",
    "# This will only make sense if you \"Run all cells\"\n",
    "tic = time.time()\n",
    "\n",
    "#nav logger = get_azureml_logger() # logger writes to AMLWorkbench runtime view\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Telemetry\n",
    "amllog.info('amlrealworld.predictivemaintenance.operationalization','true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the feature data set from memory to construct the operationalization schema. We again will require your storage account name and account key to connect to the blob storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "      <th>failure</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>2016-01-01 12:00:00</td>\n",
       "      <td>162.374561</td>\n",
       "      <td>445.713044</td>\n",
       "      <td>103.468532</td>\n",
       "      <td>39.696107</td>\n",
       "      <td>166.697820</td>\n",
       "      <td>444.924308</td>\n",
       "      <td>100.427843</td>\n",
       "      <td>40.302193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>9</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>169.634236</td>\n",
       "      <td>448.824824</td>\n",
       "      <td>100.134285</td>\n",
       "      <td>40.534216</td>\n",
       "      <td>168.831580</td>\n",
       "      <td>455.688535</td>\n",
       "      <td>98.841978</td>\n",
       "      <td>39.876219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>9</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>2015-12-31 12:00:00</td>\n",
       "      <td>168.028923</td>\n",
       "      <td>462.552245</td>\n",
       "      <td>97.549672</td>\n",
       "      <td>39.218223</td>\n",
       "      <td>165.477871</td>\n",
       "      <td>454.466625</td>\n",
       "      <td>98.704752</td>\n",
       "      <td>39.480803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>9</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "      <td>162.926820</td>\n",
       "      <td>446.381005</td>\n",
       "      <td>99.859832</td>\n",
       "      <td>39.743383</td>\n",
       "      <td>163.461431</td>\n",
       "      <td>447.678924</td>\n",
       "      <td>101.114095</td>\n",
       "      <td>39.132162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>9</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>2015-12-30 12:00:00</td>\n",
       "      <td>163.996042</td>\n",
       "      <td>448.976843</td>\n",
       "      <td>102.368357</td>\n",
       "      <td>38.520940</td>\n",
       "      <td>167.565612</td>\n",
       "      <td>448.850939</td>\n",
       "      <td>98.799875</td>\n",
       "      <td>38.876751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>9</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0         27 2016-01-01 12:00:00           162.374561             445.713044   \n",
       "1         27 2016-01-01 00:00:00           169.634236             448.824824   \n",
       "2         27 2015-12-31 12:00:00           168.028923             462.552245   \n",
       "3         27 2015-12-31 00:00:00           162.926820             446.381005   \n",
       "4         27 2015-12-30 12:00:00           163.996042             448.976843   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               103.468532                 39.696107           166.697820   \n",
       "1               100.134285                 40.534216           168.831580   \n",
       "2                97.549672                 39.218223           165.477871   \n",
       "3                99.859832                 39.743383           163.461431   \n",
       "4               102.368357                 38.520940           167.565612   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             444.924308               100.427843                 40.302193   \n",
       "1             455.688535                98.841978                 39.876219   \n",
       "2             454.466625                98.704752                 39.480803   \n",
       "3             447.678924               101.114095                 39.132162   \n",
       "4             448.850939                98.799875                 38.876751   \n",
       "\n",
       "    ...     error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum  \\\n",
       "0   ...                          0.0     504.0     564.0     444.0     399.0   \n",
       "1   ...                          0.0     504.0     564.0     444.0     399.0   \n",
       "2   ...                          0.0     503.0     563.0     443.0     398.0   \n",
       "3   ...                          0.0     503.0     563.0     443.0     398.0   \n",
       "4   ...                          0.0     502.0     562.0     442.0     397.0   \n",
       "\n",
       "    model  age    model_encoded  failure  label_e  \n",
       "0  model2    9  (0.0, 0.0, 1.0)      0.0      0.0  \n",
       "1  model2    9  (0.0, 0.0, 1.0)      0.0      0.0  \n",
       "2  model2    9  (0.0, 0.0, 1.0)      0.0      0.0  \n",
       "3  model2    9  (0.0, 0.0, 1.0)      0.0      0.0  \n",
       "4  model2    9  (0.0, 0.0, 1.0)      0.0      0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = os.getenv('STAGING_STORAGE_ACCOUNT_NAME')\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = os.getenv('STAGING_STORAGE_ACCOUNT_KEY')\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# We will create this container to hold the results of executing this notebook.\n",
    "# If this container name already exists, we will use that instead, however\n",
    "# This notebook will ERASE ALL CONTENTS.\n",
    "CONTAINER_NAME = \"featureengineering\"\n",
    "FE_DIRECTORY = 'featureengineering_files.parquet'\n",
    "\n",
    "MODEL_CONTAINER = 'modeldeploy'\n",
    "\n",
    "# Connect to your blob service     \n",
    "az_blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# Create a new container if necessary, otherwise you can use an existing container.\n",
    "# This command creates the container if it does not already exist. Else it does nothing.\n",
    "az_blob_service.create_container(CONTAINER_NAME, \n",
    "                                 fail_on_exist=False, \n",
    "                                 public_access=PublicAccess.Container)\n",
    "\n",
    "# create a local path where to store the results later.\n",
    "if not os.path.exists(FE_DIRECTORY):\n",
    "    os.makedirs(FE_DIRECTORY)\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if CONTAINER_NAME in blob.name:\n",
    "        local_file = os.path.join(FE_DIRECTORY, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "fedata = spark.read.parquet(FE_DIRECTORY)\n",
    "\n",
    "fedata.limit(5).toPandas().head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define deployment functions\n",
    "\n",
    "The init() function initializes your web service, loading in any data or models that you need to score your inputs. In the example below, we load in the trained model. This command is run when the Docker container containing your service initializes.\n",
    "\n",
    "The run() function defines what is executed on a scoring call. In our simple example, we simply load in the input as a data frame, and run our pipeline on the input, and return the prediction.\n",
    "\n",
    "Start by defining the init() and run() functions, test them with example data. Then write them to the `score.py` file for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the deployment environment\n",
    "def init():\n",
    "    # read in the model file\n",
    "    from pyspark.ml import PipelineModel\n",
    "    global pipeline\n",
    "    \n",
    "    pipeline = PipelineModel.load(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + '/' + 'pdmrfull.model')\n",
    "    \n",
    "    \n",
    "# Run the model and return the scored result.    \n",
    "def run(input_df):\n",
    "    import json\n",
    "    response = ''\n",
    "    try:\n",
    "        #Get prediction results for the dataframe\n",
    "        \n",
    "        # We'll use the known label, key variables and \n",
    "        # a few extra columns we won't need.\n",
    "        key_cols =['label_e','machineID','dt_truncated', 'failure','model_encoded','model' ]\n",
    "\n",
    "        # Then get the remaing feature names from the data\n",
    "        input_features = input_df.columns\n",
    "\n",
    "        # Remove the extra stuff if it's in the input_df\n",
    "        input_features = [x for x in input_features if x not in set(key_cols)]\n",
    "        \n",
    "        # Vectorize as in model building\n",
    "        va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "        data = va.transform(input_df).select('machineID','features')\n",
    "        score = pipeline.transform(data)\n",
    "        predictions = score.collect()\n",
    "\n",
    "        #Get each scored result\n",
    "        preds = [str(x['prediction']) for x in predictions]\n",
    "        response = \",\".join(preds)\n",
    "    except Exception as e:\n",
    "        print(\"Error: {0}\",str(e))\n",
    "        return (str(e))\n",
    "    \n",
    "    # Return results\n",
    "    print(json.dumps(response))\n",
    "    return json.dumps(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create schema file\n",
    "\n",
    "The deployment requires a schema file to define the incoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the known label, key variables and \n",
    "# a few extra columns we won't need. (machineID is required)\n",
    "key_cols =['label_e','dt_truncated', 'failure','model_encoded','model' ]\n",
    "\n",
    "# Then get the remaining feature names from the data\n",
    "input_features = fedata.columns\n",
    "# Remove the extra stuff if it's in the input_df\n",
    "input_features = [x for x in input_features if x not in set(key_cols)]\n",
    "\n",
    "# define the input data frame\n",
    "inputs = {\"input_df\": SampleDefinition(DataTypes.SPARK, \n",
    "                                       fedata.select(input_features))}\n",
    "\n",
    "json_schema = generate_schema(run_func=run, inputs=inputs, filepath='service_schema.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the functions\n",
    "\n",
    "We can then test the `init()` and `run()` functions right here in the notebook. It's about impossible to debug after publish a web service.\n",
    "\n",
    "First we get a sample test observation that we can score. For this, we can randomly select a single record from the test data we've loaded from Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>volt_rollingmean_36</th>\n",
       "      <th>...</th>\n",
       "      <th>error1sum_rollingmean_24</th>\n",
       "      <th>error2sum_rollingmean_24</th>\n",
       "      <th>error3sum_rollingmean_24</th>\n",
       "      <th>error4sum_rollingmean_24</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>169.634236</td>\n",
       "      <td>448.824824</td>\n",
       "      <td>100.134285</td>\n",
       "      <td>40.534216</td>\n",
       "      <td>168.83158</td>\n",
       "      <td>455.688535</td>\n",
       "      <td>98.841978</td>\n",
       "      <td>39.876219</td>\n",
       "      <td>166.863326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0         27           169.634236             448.824824   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               100.134285                 40.534216            168.83158   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             455.688535                98.841978                 39.876219   \n",
       "\n",
       "   volt_rollingmean_36 ...   error1sum_rollingmean_24  \\\n",
       "0           166.863326 ...                        0.0   \n",
       "\n",
       "   error2sum_rollingmean_24  error3sum_rollingmean_24  \\\n",
       "0                       0.0                       0.0   \n",
       "\n",
       "   error4sum_rollingmean_24  error5sum_rollingmean_24  comp1sum  comp2sum  \\\n",
       "0                       0.0                       0.0     504.0     564.0   \n",
       "\n",
       "   comp3sum  comp4sum  age  \n",
       "0     444.0     399.0    9  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select a record from the loaded test data.\n",
    "smple = fedata.sample(False, .8).limit(1).select(input_features)\n",
    "\n",
    "smple.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployment requires first initializing (`init()`) the environment, then running the model with the supplied data fields (`run(<data>)`). The `run()` function returns the predicted label, `0.0` indicates a healthy record, other values correspond to the component predicted to fail within the next 7 days (`1.0, 2.0, 3.0, 4.0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0.0\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"0.0\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test init() in local notebook\n",
    "init()\n",
    "\n",
    "# test run() in local notebook\n",
    "run(smple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model returned a `0.0`, indicating a healthy prediction. Comparing this to the actual value of the `label_e` variable for this record would determine how the model actually did. However we did not include this feature in the sampled data, as it would not be available in the production environment. \n",
    "\n",
    "In the following code block, we use the `filter` function to select 10 records with a specific failure label (`4.0`) indicating a failure for component 4 is probable within the next 7 days. You can see this by scrolling to the right to find the `label_e` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "      <th>failure</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>2015-11-25 12:00:00</td>\n",
       "      <td>168.495455</td>\n",
       "      <td>443.402536</td>\n",
       "      <td>101.644177</td>\n",
       "      <td>46.299947</td>\n",
       "      <td>167.738871</td>\n",
       "      <td>446.876454</td>\n",
       "      <td>99.230245</td>\n",
       "      <td>48.407601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>497.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>2015-11-25 00:00:00</td>\n",
       "      <td>166.982286</td>\n",
       "      <td>450.350373</td>\n",
       "      <td>96.816313</td>\n",
       "      <td>50.515256</td>\n",
       "      <td>167.999785</td>\n",
       "      <td>447.347369</td>\n",
       "      <td>99.122015</td>\n",
       "      <td>50.658296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>497.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>2015-11-24 12:00:00</td>\n",
       "      <td>169.017283</td>\n",
       "      <td>444.344366</td>\n",
       "      <td>101.427717</td>\n",
       "      <td>50.801335</td>\n",
       "      <td>165.798704</td>\n",
       "      <td>438.957507</td>\n",
       "      <td>101.094629</td>\n",
       "      <td>50.575573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>2015-11-23 00:00:00</td>\n",
       "      <td>173.647813</td>\n",
       "      <td>454.273713</td>\n",
       "      <td>102.275332</td>\n",
       "      <td>41.350158</td>\n",
       "      <td>170.275024</td>\n",
       "      <td>460.029772</td>\n",
       "      <td>102.038005</td>\n",
       "      <td>40.744822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>495.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>2015-11-22 12:00:00</td>\n",
       "      <td>166.902235</td>\n",
       "      <td>465.785832</td>\n",
       "      <td>101.800677</td>\n",
       "      <td>40.139485</td>\n",
       "      <td>166.653815</td>\n",
       "      <td>456.815761</td>\n",
       "      <td>100.187608</td>\n",
       "      <td>40.185250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>494.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>model2</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0         63 2015-11-25 12:00:00           168.495455             443.402536   \n",
       "1         63 2015-11-25 00:00:00           166.982286             450.350373   \n",
       "2         63 2015-11-24 12:00:00           169.017283             444.344366   \n",
       "3         63 2015-11-23 00:00:00           173.647813             454.273713   \n",
       "4         63 2015-11-22 12:00:00           166.902235             465.785832   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               101.644177                 46.299947           167.738871   \n",
       "1                96.816313                 50.515256           167.999785   \n",
       "2               101.427717                 50.801335           165.798704   \n",
       "3               102.275332                 41.350158           170.275024   \n",
       "4               101.800677                 40.139485           166.653815   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             446.876454                99.230245                 48.407601   \n",
       "1             447.347369                99.122015                 50.658296   \n",
       "2             438.957507               101.094629                 50.575573   \n",
       "3             460.029772               102.038005                 40.744822   \n",
       "4             456.815761               100.187608                 40.185250   \n",
       "\n",
       "    ...     error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum  \\\n",
       "0   ...                     0.000000     497.0     497.0     407.0     512.0   \n",
       "1   ...                     0.041667     497.0     497.0     407.0     512.0   \n",
       "2   ...                     0.041667     496.0     496.0     406.0     511.0   \n",
       "3   ...                     0.000000     495.0     495.0     405.0     510.0   \n",
       "4   ...                     0.000000     494.0     494.0     404.0     509.0   \n",
       "\n",
       "    model  age    model_encoded  failure  label_e  \n",
       "0  model2   14  (0.0, 0.0, 1.0)      4.0      4.0  \n",
       "1  model2   14  (0.0, 0.0, 1.0)      0.0      4.0  \n",
       "2  model2   14  (0.0, 0.0, 1.0)      0.0      4.0  \n",
       "3  model2   14  (0.0, 0.0, 1.0)      0.0      4.0  \n",
       "4  model2   14  (0.0, 0.0, 1.0)      0.0      4.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smple_f = fedata.filter(fedata.label_e == 4.0).sample(False, .8).limit(10)\n",
    "smple_f.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have already initialized the environment, we can submit this new record to the model for scoring. We need the record to align with the specified scheme, so we select out the features according to the `input_features` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"3.0,3.0,3.0,0.0,0.0,0.0,3.0,3.0,3.0,0.0\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"3.0,3.0,3.0,0.0,0.0,0.0,3.0,3.0,3.0,0.0\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(smple_f.select(input_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the output of this to the actual value indicates a mismatch in the failure prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assets\n",
    "\n",
    "Next we package the model assets into a zip file and store them to azure blob deployment into an operationalization environment. First write out the tested assets to local storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the schema file for deployment\n",
    "out = json.dumps(json_schema)\n",
    "#nav with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'service_schema.json', 'w') as f:\n",
    "with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + '/' + 'service_schema.json', 'w') as f:\n",
    "    f.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `%%writefile` meta command to save the `init()` and `run()` functions to the `pdmscore.py` file. Because of how the `%%writefile` command works, we have to copy these functions from the tested versions above into this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/navig/mnt/azureml-share/pdmscore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']}/pdmscore.py\n",
    "\n",
    "\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier\n",
    "\n",
    "# for creating pipelines and model\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "\n",
    "def init():\n",
    "    # read in the model file\n",
    "    from pyspark.ml import PipelineModel\n",
    "    # read in the model file\n",
    "    global pipeline\n",
    "    pipeline = PipelineModel.load('pdmrfull.model')\n",
    "    \n",
    "def run(input_df):\n",
    "    response = ''\n",
    "    try:\n",
    "       \n",
    "        # We'll use the known label, key variables and \n",
    "        # a few extra columns we won't need.\n",
    "        key_cols =['label_e','machineID','dt_truncated', 'failure','model_encoded','model' ]\n",
    "\n",
    "        # Then get the remaing feature names from the data\n",
    "        input_features = input_df.columns\n",
    "\n",
    "        # Remove the extra stuff if it's in the input_df\n",
    "        input_features = [x for x in input_features if x not in set(key_cols)]\n",
    "        \n",
    "        # Vectorize as in model building\n",
    "        va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "        data = va.transform(input_df).select('machineID','features')\n",
    "        score = pipeline.transform(data)\n",
    "        predictions = score.collect()\n",
    "\n",
    "        #Get each scored result\n",
    "        preds = [str(x['prediction']) for x in predictions]\n",
    "        response = \",\".join(preds)\n",
    "    except Exception as e:\n",
    "        print(\"Error: {0}\",str(e))\n",
    "        return (str(e))\n",
    "    \n",
    "    # Return results\n",
    "    print(json.dumps(response))\n",
    "    return json.dumps(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    run(\"{\\\"input_df\\\":[{\\\"machineID\\\":114,\\\"volt_rollingmean_3\\\":163.375732902,\\\"rotate_rollingmean_3\\\":333.149484586,\\\"pressure_rollingmean_3\\\":100.183951698,\\\"vibration_rollingmean_3\\\":44.0958812638,\\\"volt_rollingmean_24\\\":164.114723991,\\\"rotate_rollingmean_24\\\":277.191815232,\\\"pressure_rollingmean_24\\\":97.6289110707,\\\"vibration_rollingmean_24\\\":50.8853505161,\\\"volt_rollingstd_3\\\":21.0049565219,\\\"rotate_rollingstd_3\\\":67.5287259378,\\\"pressure_rollingstd_3\\\":12.9361526861,\\\"vibration_rollingstd_3\\\":4.61359760918,\\\"volt_rollingstd_24\\\":15.5377738062,\\\"rotate_rollingstd_24\\\":67.6519885441,\\\"pressure_rollingstd_24\\\":10.528274633,\\\"vibration_rollingstd_24\\\":6.94129487555,\\\"error1sum_rollingmean_24\\\":0.0,\\\"error2sum_rollingmean_24\\\":0.0,\\\"error3sum_rollingmean_24\\\":0.0,\\\"error4sum_rollingmean_24\\\":0.0,\\\"error5sum_rollingmean_24\\\":0.0,\\\"comp1sum\\\":489.0,\\\"comp2sum\\\":549.0,\\\"comp3sum\\\":549.0,\\\"comp4sum\\\":564.0,\\\"age\\\":18.0}]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are stored in the `['AZUREML_NATIVE_SHARE_DIRECTORY']` location on the kernel host machine with the model stored in the `3_model_building.ipynb` notebook. In order to share these assets and operationalize the model, we create a new blob container and store a compressed file containing those assets for later retrieval from the deployment location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full run took 0.48 minutes\n"
     ]
    }
   ],
   "source": [
    "# Compress the operationalization assets for easy blob storage transfer\n",
    "MODEL_O16N = shutil.make_archive('o16n', 'zip', os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'])\n",
    "\n",
    "# Create a new container if necessary, otherwise you can use an existing container.\n",
    "# This command creates the container if it does not already exist. Else it does nothing.\n",
    "az_blob_service.create_container(MODEL_CONTAINER, \n",
    "                                 fail_on_exist=False, \n",
    "                                 public_access=PublicAccess.Container)\n",
    "\n",
    "# Transfer the compressed operationalization assets into the blob container.\n",
    "az_blob_service.create_blob_from_path(MODEL_CONTAINER, \"o16n.zip\", str(MODEL_O16N) ) \n",
    "\n",
    "\n",
    "# Time the notebook execution. \n",
    "# This will only make sense if you \"Run All\" cells\n",
    "toc = time.time()\n",
    "print(\"Full run took %.2f minutes\" % ((toc - tic)/60))\n",
    "\n",
    "amllog.info(\"Operationalization Run time\", ((toc - tic)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "Once the assets are stored, we can download them into a deployment compute context for operationalization on an Azure web service. For this scenario, we will deploy this on our local context.\n",
    "\n",
    "We demonstrate how to setup this web service this through a CLI window opened in the AML Workbench application. \n",
    "\n",
    "## Download the model\n",
    "\n",
    "To download the model we've saved, follow these instructions on a local computer.\n",
    "\n",
    "- Open the [Azure Portal](http://portal.azure.com)\n",
    "- In the left hand pane, click on __All resources__\n",
    "- Search for the storage account using the name you provided earlier in this notebook. \n",
    "- Choose the storage account from search result list, this will open the storage account panel.\n",
    "- On the storage account panel, choose __Blobs__\n",
    "- On the Blobs panel choose the container __modeldeploy__\n",
    "- Select the file o16n.zip and on the properties pane for that blob choose download.\n",
    "\n",
    "Once downloaded, unzip the file into the directory of your choosing. The zip file contains three deployment assets:\n",
    "\n",
    "- the `pdmscore.py` file\n",
    "- a `pdmrfull.model` directory\n",
    "- the `service_schema.json` file\n",
    "\n",
    "## Create a model management endpoint \n",
    "\n",
    "Create a modelmanagement under your account. We will call this `pdmmodelmanagement`. The remaining defaults are acceptable.\n",
    "\n",
    "`az ml account modelmanagement create --location <ACCOUNT_REGION> --resource-group <RESOURCE_GROUP> --name pdmmodelmanagement`\n",
    "\n",
    "If you get a `ResourceGroupNotFound` error, you may need to set the correct subscription. This is typically only an issue if your Azure login connects to multiple subscritpions. \n",
    "\n",
    "`az account set -s '<subscription name>'`\n",
    "\n",
    "You can find the `subscription name` or `subscription id` through the (https://portal.azure.com) under the resource group you'd like to use.\n",
    "\n",
    "## Check environment settings\n",
    "\n",
    "Show what environment is currently active:\n",
    "\n",
    "`az ml env show`\n",
    "\n",
    "If nothing is set, we setup the environment with the existing model management context first: \n",
    "\n",
    "` az ml env setup --location <ACCOUNT_REGION> --resource-group <RESOURCE_GROUP> --name pdmmodelmanagement`\n",
    "\n",
    "using the same `<ACCOUNT_REGION>` and `<RESOURCE_GROUP>` in the previous section. Then set the current environment:\n",
    "\n",
    "`az ml env set --resource-group <RESOURCE_GROUP> --cluster-name pdmmodelmanagement`\n",
    "\n",
    "Check that the environment is now set:\n",
    "\n",
    "`az ml env show`\n",
    "\n",
    "\n",
    "## Install docker to compute target\n",
    "\n",
    "Once the model management environment is setup, we'll deploy the web service from the CLI to a local docker container for this demonstration. This assumes you have docker installed localy (https://www.docker.com/get-docker).\n",
    "\n",
    "Once docker is installed and running, you will need to prepare the local docker container, just as we didi the remote container.\n",
    "\n",
    "`az ml experiment prepare -c docker`\n",
    "\n",
    "Now deploy the solution to this container.\n",
    "\n",
    "\n",
    "## Deploy a web service \n",
    "\n",
    "These commands assume the current directory contains the webservice assets we created in throughout the notebooks in this scenario (`pdmscore.py`, `service_schema.json` and `pdmrfull.model`). Change to the directory where the zip file was unpacked. \n",
    "\n",
    "The command to create a web service (`<SERVICE_ID>`) with these operationalization assets in the current directory is:\n",
    "\n",
    "```\n",
    "az ml service create realtime -f <filename> -r <TARGET_RUNTIME> -m <MODEL_FILE> -s <SCHEMA_FILE> -n <SERVICE_ID> --cpu 0.1\n",
    "```\n",
    "\n",
    "The default cluster has only 2 nodes with 2 cores each. Some cores are taken for system components. AMLWorkbench asks for 1 core per service. To deploy multiple services into this cluster, we specify the cpu requirement in the service create command as (--cpu 0.1) to request 10% of a core. \n",
    "\n",
    "For this example, we will call our webservice `amlworkbenchpdmwebservice`. This `SERVICE_ID` must be all lowercase, with no spaces:\n",
    "\n",
    "```\n",
    "az ml service create realtime -f pdmscore.py -r spark-py -m pdmrfull.model -s service_schema.json --cpu 0.1 -n amlworkbenchpdmwebservice\n",
    "```\n",
    "\n",
    "This command will take some time to execute. \n",
    "\n",
    "## Test your deployment.\n",
    "\n",
    "Once complete, the `az ml service create` command returns sample usage commands to test the service for both PowerShell and the cmd prompt. We can test this deployment by executing these commands from the command line. For our example:\n",
    "\n",
    "```\n",
    " az ml service run realtime -i amlworkbenchpdmwebservice --% -d \"{\\\"input_df\\\": [{\\\"rotate_rollingmean_36\\\": 450.0384342542265, \\\"rotate_rollingstd_36\\\": 0.0, \\\"volt_rollingmean_24\\\": 166.69782028530955, \\\"volt_rollingmean_36\\\": 166.5072079613422, \\\"comp1sum\\\": 504.0, \\\"comp2sum\\\": 564.0, \\\"error3sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingmean_24\\\": 40.302192663278625, \\\"pressure_rollingstd_24\\\": 0.0, \\\"vibration_rollingstd_12\\\": 0.0, \\\"pressure_rollingstd_12\\\": 0.0, \\\"rotate_rollingmean_12\\\": 445.7130438343768, \\\"volt_rollingstd_24\\\": 0.0, \\\"comp3sum\\\": 444.0, \\\"error1sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingstd_36\\\": 0.0, \\\"rotate_rollingstd_24\\\": 0.0, \\\"volt_rollingstd_36\\\": 0.0, \\\"rotate_rollingmean_24\\\": 444.92430808877185, \\\"error2sum_rollingmean_24\\\": 0.0, \\\"pressure_rollingstd_36\\\": 0.0, \\\"comp4sum\\\": 399.0, \\\"machineID\\\": 27, \\\"pressure_rollingmean_24\\\": 100.42784289855126, \\\"volt_rollingmean_12\\\": 162.37456132546583, \\\"error4sum_rollingmean_24\\\": 0.0, \\\"pressure_rollingmean_12\\\": 103.46853199581041, \\\"age\\\": 9, \\\"pressure_rollingmean_36\\\": 99.1626730910439, \\\"volt_rollingstd_12\\\": 0.0, \\\"rotate_rollingstd_12\\\": 0.0, \\\"vibration_rollingmean_36\\\": 39.86004229336383, \\\"vibration_rollingstd_24\\\": 0.0, \\\"error5sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingmean_12\\\": 39.69610732198209}, {\\\"rotate_rollingmean_36\\\": 452.58602482190344, \\\"rotate_rollingstd_36\\\": 1.3063227195446807, \\\"volt_rollingmean_24\\\": 168.8315798036505, \\\"volt_rollingmean_36\\\": 166.8633264221902, \\\"comp1sum\\\": 504.0, \\\"comp2sum\\\": 564.0, \\\"error3sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingmean_24\\\": 39.8762193116053, \\\"pressure_rollingstd_24\\\": 0.5506261833397947, \\\"vibration_rollingstd_12\\\": 0.5581845837178677, \\\"pressure_rollingstd_12\\\": 1.3059590035299573, \\\"rotate_rollingmean_12\\\": 448.82482383859184, \\\"volt_rollingstd_24\\\": 1.1327450423992658, \\\"comp3sum\\\": 444.0, \\\"error1sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingstd_36\\\": 0.12802019423837702, \\\"rotate_rollingstd_24\\\": 6.2252625510326345, \\\"volt_rollingstd_36\\\": 1.2113288898088435, \\\"rotate_rollingmean_24\\\": 455.68853459771736, \\\"error2sum_rollingmean_24\\\": 0.0, \\\"pressure_rollingstd_36\\\": 0.360813923769749, \\\"comp4sum\\\": 399.0, \\\"machineID\\\": 27, \\\"pressure_rollingmean_24\\\": 98.84197839575184, \\\"volt_rollingmean_12\\\": 169.6342364499553, \\\"error4sum_rollingmean_24\\\": 0.0, \\\"pressure_rollingmean_12\\\": 100.13428527324218, \\\"age\\\": 9, \\\"pressure_rollingmean_36\\\": 99.18126302139088, \\\"volt_rollingstd_12\\\": 1.7162303092954838, \\\"rotate_rollingstd_12\\\": 7.358009183124642, \\\"vibration_rollingmean_36\\\": 39.83194043387068, \\\"vibration_rollingstd_24\\\": 0.26866456414969686, \\\"error5sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingmean_12\\\": 40.534215611846555}, {\\\"rotate_rollingmean_36\\\": 452.6366978657443, \\\"rotate_rollingstd_36\\\": 0.726203655443797, \\\"volt_rollingmean_24\\\": 165.47787140830766, \\\"volt_rollingmean_36\\\": 164.9839282666808, \\\"comp1sum\\\": 503.0, \\\"comp2sum\\\": 563.0, \\\"error3sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingmean_24\\\": 39.48080284488274, \\\"pressure_rollingstd_24\\\": 0.43573594568766316, \\\"vibration_rollingstd_12\\\": 0.33150005427630586, \\\"pressure_rollingstd_12\\\": 0.30398746497620055, \\\"rotate_rollingmean_12\\\": 462.5522453568429, \\\"volt_rollingstd_24\\\": 1.388783538126311, \\\"comp3sum\\\": 443.0, \\\"error1sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingstd_36\\\": 0.06733738203927228, \\\"rotate_rollingstd_24\\\": 2.2615583783043336, \\\"volt_rollingstd_36\\\": 0.4066137169118576, \\\"rotate_rollingmean_24\\\": 454.4666253135592, \\\"error2sum_rollingmean_24\\\": 0.0, \\\"pressure_rollingstd_36\\\": 0.40800640702349306, \\\"comp4sum\\\": 398.0, \\\"machineID\\\": 27, \\\"pressure_rollingmean_24\\\": 98.70475189546528, \\\"volt_rollingmean_12\\\": 168.0289231573457, \\\"error4sum_rollingmean_24\\\": 0.0, \\\"pressure_rollingmean_12\\\": 97.5496715182615, \\\"age\\\": 9, \\\"pressure_rollingmean_36\\\": 99.92595364177775, \\\"volt_rollingstd_12\\\": 1.9026812928919759, \\\"rotate_rollingstd_12\\\": 12.545522310840685, \\\"vibration_rollingmean_36\\\": 39.16084871098736, \\\"vibration_rollingstd_24\\\": 0.2757178837764945, \\\"error5sum_rollingmean_24\\\": 0.0, \\\"vibration_rollingmean_12\\\": 39.21822301136402}]}\"\n",
    "```\n",
    "This submits 3 records to the model through the web service, and returns predictioned output labels for each of the three rows:\n",
    "\n",
    "```\n",
    "\"0.0,0.0,0.0\"\n",
    "```\n",
    "\n",
    "Indicating that these records are predicted to be healthy with in the requested 7 day time window.\n",
    "\n",
    "\n",
    "We can view additional service usage information with the following command. \n",
    "\n",
    "```az ml service usage realtime -i amlworkbenchpdmwebservice```\n",
    "\n",
    "Which indicates how the service is currently deployed:\n",
    "\n",
    "```\n",
    "Scoring URL:\n",
    "    http://127.0.0.1:32770/score\n",
    "\n",
    "Headers:\n",
    "    Content-Type: application/json\n",
    "\n",
    "Swagger URL:\n",
    "    http://127.0.0.1:32770/swagger.json\n",
    "\n",
    "Sample CLI command:\n",
    "...\n",
    "```\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Working through all of these notebooks, we have completed:\n",
    "\n",
    " * Data aquisition in `Code/1_data_aquisition.ipynb` notebook.\n",
    " * Time series feature engineering and failure labeling to predict component failures within a 7 day window in the `Code/2_feature_engineering.ipynb` notebook.\n",
    " * Model building and evaluation in the `Code/3_model_building.ipynb` notebook.\n",
    " * Deployment asset generation and model deployment in the `Code/4_operationalization.ipynb` notebook.\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Spark - local",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
